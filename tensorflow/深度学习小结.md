# 深度学习
## 1.背景
  计算机诞生之后，大量问题得到了相对于人工更好地解决方案，但是对于图像识别，自然语言等领域，计算机无法与人相比较。上世纪四十年代，借鉴神经学研究，提出感知机的概念
  
 ## 2.感知机
 模仿大脑神经元的结构，提取出事物的特征值，并制定特征值对应的权重，计算权重的加权和，得出判断结果
 以判断一封邮件是否为垃圾邮件为例，通常人工判断一封邮件是否为垃圾邮件，可能会参考网址和题目。使用感知机计算图如图1-1

 ![image](https://note.youdao.com/yws/api/personal/file/061B18CE94F54AA79A7A667CEEE57B1F?method=download&shareKey=d5698f398a5f6878bc1d9ba64e4d18f1 "1-1感知机")
 ######  图1
 
 上图中，X1代表网址，X2代表题目，这里X1,X2称为该问题的特征值。w1，w2为两个特征值的权重，那么Y=X1*w1+X2*w2，对y加门限判断，最终得到结果。
 
 
 ## 3.前向传播算法
 以上定义的是一个一层的神经网络。对于一个问题的判断，例如自然语言等，往往需要抽离出更高维度的特征值，所以我们一般所运用得往往是深层神经网络，结构如图2
 
 ![image](https://note.youdao.com/yws/api/personal/file/83B3981AB6964436B1BDAB855E8ACDCC?method=download&shareKey=b12210b0a2872c2ff456495b855a2c6e)
######  图2
 
上图A1,A2称为隐藏层，X1,X2称为输入层，Y称为输出层。隐藏层实际是抽象出更高维度的特征值。由输入层到输出层实现称为前向传播算法。
前向传播算法可以用矩阵的方式做表示，图2用矩阵表示如下
    
```math
A=XW
```
```math
Y=Aa=XWa
```
由上述推倒可知，对于符合线性模型的任意层神经网络，表达能力上与一层神经网络没有区别。线性模型在向量空间中为直线或一个平面，在现实世界中，绝大部分问题无法进行线性分割。所以，需要去线性化处理

## 4.激活函数与偏置项
为了解决上述的线性不可分问题，我们引入激活函数，图2隐藏层表述如下
A=f(x*W+b)
其中f称为激活函数，b称为偏置量。激活函数实际上是对加权和的计算结果做了非线性变换，实现了去线性化

通过前向传播算法，计算机可以对一个问题做出判断。但是，神经网络参数（权重），必须预先设置。为了解决神经网络参数自动调优，提出**反向传播算法**对神经网络进行训练

## 5.神经网络训练与反向传播算法
神经网络训练流程：

![image](https://note.youdao.com/yws/public/resource/3c7ea60f8212c57267ddd07791ad313d/xmlnote/F96A0283D4004A4BA6360A0F366388A1/1307 "神经网络训练流程")


为了解决神经网络参数自适应，往往输入训练集的方式，按照神经网络输出结果，计算输出结果与训练集真实结果的交叉熵进行参数准确度判断，从而对神经网络参数调优。这个过程称为反向传播算法

### 5.1损失函数（交叉熵）
交叉熵刻画的是两个概率分布之间的距离，当交叉熵越小，说明预测值与真实值越接近，参数越准。由于交叉熵描述的是概率距离，所以要将预测值变成概率分布，常用的有softmax
## 6神经网络优化与学习率
 
 